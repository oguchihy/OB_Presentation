---
title: "OB DATA Analytics"
author: "Oguchi Nkwocha, MD., MS"
format:
  html:
    page-layout: full
    code-tools: true
server: shiny
---

To learn more about Quarto see <https://quarto.org>.

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(readr)
library(openxlsx)
library(xlsx)
library(DataExplorer)
library(explore)
library(XICOR)
library(survival)
library(survminer)
library(klaR)
library(ggforestplot)
library(forestplot) 
library(myRFunctions)
library(mice)
library(readxl)
library(dplyr)
library(purrr)
library(stringr)
library(randomForest)
library(leaflet)
library(sf)
library(tableone)
library(DT)
library(kableExtra)


```

```{r echo = FALSE}
ob_data_chr <- readRDS("Working OB Dataset.RDS")
ob_data_fctr <- readRDS("All Factored Complete Ready OB Dataset for Analytics.RDS")
```


# CSVS OB DATA Analytics

```{r echo = FALSE, warning=FALSE, message=FALSE}
ob_stats_block <- ob_data_chr

# Calculate days and months
library(lubridate)

# Define start and end dates
ob_data_orig <- readRDS("Base OB Data DB.RDS")
start_date <- min(ob_data_orig$adm_date)
end_date <- max(ob_data_orig$adm_date)

# Calculate the number of days
number_of_days <- as.numeric(end_date - start_date)
#print(paste("Number of days:", number_of_days))

# Calculate the number of months
date_interval <- interval(start_date, end_date)
number_of_months <- time_length(date_interval, "months")
#print(paste("Number of months:", number_of_months))

# Other quick stats

dte_range_NMC_data <- range(ob_stats_block$adm_date)
del_tm_dur_range <- round(range((ob_stats_block$gest_age_days)/7),1)
age_range <- range(ob_stats_block$age)
nbr_del_nmc <- nrow(ob_stats_block)
prcnt_preterm <- round(sum(ob_stats_block$gest_age_days <259) / sum(ob_stats_block$gest_age_days >=140)*100,0)
gest_age_range <- range(ob_stats_block$gest_age_days, na.rm = TRUE)
prcnt_hghRsk <- round(sum(ob_stats_block$hghRsk=="yes")/nrow(ob_stats_block)*100,0)
mltpl_gest <- sum(ob_data_chr$baby_sq>1)
mltpl_gest_prcnt <- round(mltpl_gest/nrow(ob_data_chr)*100,1)
mltpl_gest_lvls <- levels(factor(ob_data_chr$baby_sq))
gndr <- table(ob_data_chr$gender)
gndr_prcnt <- round(prop.table(gndr)*100,1)
c_section <- sum(ob_stats_block$del_method_cnsldt!="Vaginal")
c_section_prcnt <- round(c_section / nrow(ob_stats_block)*100,1)
prim_c_section <- sum(ob_stats_block$del_method_cnsldt=="Cesarean Section, Primary")
prim_c_section_prcnt <- round(prim_c_section/c_section*100, 1)

ave_daily_del <- round(nrow(ob_stats_block)/number_of_days,0)
ave_monthly_del <- round(nrow(ob_stats_block)/number_of_months,0)
```

## Overview

Between `r dte_range_NMC_data[1]` and `r dte_range_NMC_data[2]`, a period of **9 quarters** or 27 months, ***`r nbr_del_nmc`*** CSVS prenatal patients delivered at NMC, which is the principal source of data for this analysis.This included **```r gndr[1]``` females**, **```r gndr[2]``` males** and **```r gndr[3]``` unknowns** (```r gndr_prcnt[c(1:3)]``` % respectively). There were **```r mltpl_gest``` multiple gestations** --all twins -- a ```r mltpl_gest_prcnt```% incidence. 

Cesarean section rate was **```r c_section_prcnt```%**; **```r prim_c_section_prcnt```%** of the sections were **Primary**. There was **1 Fetal Demise** during the period.

In summary, the average monthly delivery for CSVS for the period was **```r ave_monthly_del```**. Each day, on the average, **```r ave_daily_del``` deliveries** occurred.

Maternal age range was between ***`r age_range[1]`*** and ***`r age_range[2]`***, with a ***median age of `r median(ob_stats_block$age)`***. (See Histogram below)

```{r echo=FALSE, warning=FALSE}
library(lattice)
histogram(~ age, data = ob_data_chr, xlab = "Age")
```

Delivery Data for our patients at NMC is kept in NMC OB Delivered Log repository; it captures the following types and categories of information relevant to our analysis:

##### **FIELDS & Names**
```{r echo=FALSE, warning=FALSE}
library(knitr)
col_names_nmc <- names(ob_data_chr)
# Omit the last 9 column names
col_names_nmc <- head(col_names_nmc, -12)

# Determine the number of rows needed for three columns
n <- length(col_names_nmc)
n_rows <- ceiling(n / 3)

# Pad the column names with NA to fit the matrix
col_names_nmc <- c(col_names_nmc, rep(NA, 3 * n_rows - n))

# Create a matrix with 3 columns
col_matrix <- matrix(col_names_nmc, ncol = 3, byrow = TRUE)

# Convert the matrix to a data frame for better printing
col_df <- as.data.frame(col_matrix)

# Print the table using kable for better formatting in Quarto
kableExtra::kable(col_df, col.names = NULL, caption = "FIELDS & Names")
```

To facilitate analyses, we initially added these derived columns below:

```{r echo=FALSE, warning=FALSE}
column_names <- data.frame(Column_Names = names(ob_data_chr))
derived_cols <- data.frame(column_names[(nrow(column_names) - 12):nrow(column_names), ]) 
colnames(derived_cols) =NULL
derived_cols_df <- data.frame(Derived_column = derived_cols,
                              Explanation = c("gestational age in DAYS", "Admission-to-Delivery time", "grav minus para", "Delivery", "Duration: Delivery time minus Admit time",
                           "Duration ranges", "Age ranges used by UDS", "High Risk OB by definition", "Consolidated intrapartum conditions",
                            "Consolidated labor types", "Consolidated presentation","Consolidated Delivery method" , "Clustering groups"))
kable(derived_cols_df, caption = "Derived Fields")
```

## Exploring descriptive statistics for each variable in the dataset.

```{r echo=FALSE, warning=FALSE}
# Load necessary libraries
library(shiny)
library(tableone)
library(dplyr)
library(DT)
library(kableExtra)


ob_data_tbl1 <- readRDS("All Factored Complete Ready OB Dataset for Analytics.RDS") %>% 
  select(-adm_date, -delivery_date) %>% 
  mutate(cluster = if_else(cluster == 2,1,0))
practiceTbl <- CreateTableOne(data = ob_data_tbl1)
vars <- setdiff(names(ob_data_chr), "gest_age")
practiceTbl_no_gest_age <- CreateTableOne(data = ob_data_tbl1, vars = vars)

#Num vars
num_var_ds <- ob_data_tbl1 %>% 
  select_if(is.numeric) %>% 
  select(-event, -cluster)

num_var_Tbl <- CreateTableOne(data = num_var_ds)
num_var_prn <- kableone(print(num_var_Tbl))

# Cat vars
non_num_var_ds <- ob_data_tbl1 %>%
  select(-c(age, grav, para, weight, apg1, apg5, diff_grav_para, gest_age_days, adm_to_del_tm))
vars <- setdiff(names(non_num_var_ds), "gest_age")
non_num_var_no_gest_age <- CreateTableOne(data = non_num_var_ds, vars = vars)
cat_var_prn <- kableone(print(non_num_var_no_gest_age))
#print(practiceTbl, showAllLevels = TRUE)

# practiceTbl$CatTable
# practiceTbl$ContTable
#practiceTbl$MetaData

strata_tbl_clst <- CreateTableOne(data = ob_data_tbl1, strata = "cluster", vars = "zip")
#strt_clst_prn <- print(strata_tbl_clst, nonnormal = "cluster", cramVars = "cluster")

strata_tbl_hghRsk <- CreateTableOne(data = ob_data_tbl1, strata = "hghRsk", vars = "zip")
#strt_hghRsk_prn <- print(strata_tbl_hghRsk, nonnormal = "cluster", cramVars = "hghRsk" )

# Use Kable / KableExtra/ kableone

cat_tbl <- kableone(practiceTbl$CatTable)
#kableExtra::kable(cat_tbl, format = "html" )
#cat_tbl

cont_tbl <- kableone(practiceTbl$ContTable)
#kableExtra::kable(cont_tbl, format = "html")
#cont_tbl

strata_tbl_clst <- CreateTableOne(data = ob_data_tbl1, strata = "cluster", vars = "zip")
#print(strata_tbl_clst, nonnormal = "cluster", cramVars = "cluster" )
#kableone(print(strata_tbl_clst, nonnormal = "cluster", cramVars = "cluster" ))
#kableExtra::kable(kableone(strta_zip_clst_prn), format = "html")

strata_tbl_hghRsk <- CreateTableOne(data = ob_data_tbl1, strata = "hghRsk", vars = "zip")
#print(strata_tbl_hghRsk, nonnormal = "cluster", cramVars = "hghRsk" )
#kableone(print(strata_tbl_hghRsk, nonnormal = "cluster", cramVars = "hghRsk"))
#kableExtra::kable(kableone(strta_zip_hghRsk_prn), format = "html")

strata_tbl_clst_rsk <- CreateTableOne(data = ob_data_tbl1, strata = "hghRsk", vars = "cluster")
#print(strata_tbl_hghRsk, nonnormal = "cluster", cramVars = "hghRsk" )
#kableone(print(strata_tbl_clst_rsk, nonnormal = "hghRs", cramVars = "ghgRsk"))
#kableExtra::kable(kableone(strta_zip_hghRsk_prn), format = "html")


```

##### Let's summarize the CSVS data from NMC Delivery Log, starting with:

Numeric Variables
```{r, echo=FALSE, message=FALSE, warning=FALSE}
num_var_prn
```

Histograms
```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(reshape2)

num_var_hist <- num_var_ds %>% 
  dplyr::select(age, grav, para, weight, apg1, apg5, diff_grav_para, gest_age_days, adm_to_del_tm) 
num_var_long <- reshape2::melt(num_var_hist, variable.name = "Variable", value.name = "Value")

# Create the faceted histogram using ggplot2
ggplot(num_var_long, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "blue", color = "black", alpha = 0.7) +
  facet_wrap(~ Variable, scales = "free_x", ncol = 3) +
  labs(title = "Faceted Histogram of Numerical Variables",
       x = "Value",
       y = "Frequency") +
  theme_minimal()


```

and...

Non Numeric Variables, which we will explore interactively.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# 
# cat_var_prn
```

##### Interactive: first select variable, then Upate Table

```{r echo=FALSE}
# Load necessary libraries
library(shiny)
library(tableone)
library(dplyr)

# Load your data frame
ob_data_tbl1_shny <- readRDS("All Factored Complete Ready OB Dataset for Analytics.RDS") %>% 
  dplyr::select(-c(age, grav, para, weight, apg1, apg5, diff_grav_para, gest_age_days, adm_to_del_tm, gest_age, adm_date, delivery_date, event, time, baby_sq)) %>% 
  dplyr::mutate(cluster = as.factor(if_else(cluster == 2, 1, 0)))
```

```{r}
#| panel: sidebar
selectInput("variable", "Select a Variable:", choices = names(ob_data_tbl1_shny))
actionButton("update", "Update Table")

```

```{r}
#| panel: fill
tableOutput("table_one")

```

```{r}
#| context: server
ob_data_tbl1_shny <- readRDS("All Factored Complete Ready OB Dataset for Analytics.RDS") %>% 
  dplyr::select(-c(age, grav, para, weight, apg1, apg5, diff_grav_para, gest_age_days, adm_to_del_tm, gest_age, adm_date, delivery_date, event, time, baby_sq)) %>% 
  dplyr::mutate(cluster = as.factor(if_else(cluster == 2, 1, 0)))

# Reactive expression to get the selected variable
selected_var <- reactive({
  req(input$variable)
  input$variable
})

# Reactive expression to generate the CreateTableOne object when the update button is clicked
table_one_data <- eventReactive(input$update, {
  tableone::CreateTableOne(data = ob_data_tbl1_shny, vars = selected_var())
})

# Render the table output
output$table_one <- renderTable({
  table_df <- as.data.frame(print(table_one_data(), printToggle = FALSE))
  table_df
}, rownames = TRUE)

```

Exploratory Data analyses yields rich information. However, we need to proceed with analytics so we can query the data in order to get desired information. We need to know how variables of interest affect one another, and how they compare with one another in their contribution to the results or outcome of interest to us. The outcome of interest to us in OB can be found in prenatal care (before delivery), during delivery; the event of delivery itself and right after delivery.For example, one pre-delivery outcome is pre-term (prematurity) status; another is High Risk OB status. During delivery, we are concerned about outcomes categorized by "intrapartal conditions" such as preeclampsia and also "intrapartal events" which encompass abnormal labor dynamics. Did delivery occur at all? How long was admission-time to delivery-time? What are the chances that at a given time delivery will have occurred, and what percent of patients will have delivered by a certain time? For each of these outcomes or combinations thereof, our interest is how and if variables like maternal age, zip code, parity, high risk status, affected the end-result.

A question that's natural to ask is how residential geography affects OB outcomes. We will use zipcode information (variable, "zip) and a MAP to explore this. High Risk OB is a technical definition; we can explore what contributes to it, as well as determine how it affects other outcomes as mentioned above. A fundamental method in statistical data analytics is to "dump" all the data defined by some criteria together and see if there will be a natural separation into groups, called clustering, that achieve statistical significance. If we can find clusters and relate them to known variables, we can also use this along with zip and high risk status as a probe with whihc to analyze outcomes.

We applied cluster statistics on the data using fetal weight against gestational age: here is our finding: 

### Cluster Analysis 

Right now, we are going to look into the important OB metrics of Gestational Age and Birth weight of our patients. We will use Cluster Analysis^[Cluster analysis is a statistical technique used to group sets of objects in such a way that objects in the same group are more similar to each other than to those in other groups. It is especially useful in medical research for identifying patterns among patients, aiding in understanding behaviors, disease progression, and treatment outcomes without predefined categories.], a useful method in medical research for identifying patterns among patients that help to characterize clinical states and associated risks and treatment outcomes without predefined categories.

Using k-means clustering algorithm with a choice of 3 clusters (based on clinical relevance), we obtained these stats and plot.

```{r echo=FALSE, warning=FALSE}
#Cluster Analysis----

#setwd(getwd())
ob_clustering <- ob_data_fctr %>% 
  dplyr::select(age, gest_age_days, weight)

ob_clustering_scaled <- scale(ob_clustering)


# Cluster Analysis
set.seed(333)

# Perform K-means clustering
k <- 3
kmeans_result <- kmeans(ob_clustering_scaled, centers = k, nstart = 25)
 
# Add the cluster assignments to the original dataset
#Remove current var cluster
ob_data_fctr$cluster <- NULL
ob_data_fctr$cluster <- as.factor(kmeans_result$cluster)
 
# Map numeric cluster IDs to meaningful names
cluster_names <- c("Term, full", "Term, early",   "Pre-term")
names(cluster_names) <- 1:3
ob_data_fctr$cluster <- factor(ob_data_fctr$cluster, levels = 1:3, labels = cluster_names)

# Now, summarizing clusters with across
cluster_summary <- ob_data_fctr %>%
    group_by(cluster) %>%
    summarise(
        across(
            .cols = c(gest_age_days, weight),
            .fns = ~ round(mean(.), 0),
            .names = "mean {.col}"
        )
    )

#kable(cluster_summary, caption = "Cluster Stats")


# Plotting
library(ggplot2)

p <- ggplot(ob_data_fctr, aes(x = gest_age_days, y = weight, color = cluster)) +
    geom_point(alpha = 0.5) +
    #geom_hline(yintercept = 3000, linetype = "dashed", color = "red") +
    #geom_vline(xintercept = 259, linetype = "dashed", color = "blue") +
    theme_minimal() +
    scale_x_continuous(
        name = "Gestational Age in completed Weeks",  # Rename the x-axis to "Weeks"
        breaks = seq(0, max(ob_data_fctr$gest_age_days), by = 7),  # Set breaks every 7 days
        labels = function(x) floor(x / 7)  # Convert days to floor weeks
    ) +
    labs(title = "Cluster Analysis on Gestational Age and Birth Weights",
         x = "Gestational Age", y = "Delivery Birthweightin grams")

p

```

Can we identify this cluster grouping using known and relevant OB metrics for birth weight and gestational age categorization?

```{r}
# Plotting
library(ggplot2)
id_clust <- p +
geom_hline(yintercept = 3000, linetype = "dashed", color = "red") +
geom_vline(xintercept = 259, linetype = "dashed", color = "blue") 
id_clust 

kable(cluster_summary, caption = "Cluster Stats")
  
```


The plot shows the separation of a left lower quad (LLQ) cluster from an un-separated 2 other clusters. Further analysis shows that the LLQ cluster is statistically significantly different from either of the 2 other clusters, while this is not the case between the 2 clusters themselves. By adding the 3000 GRAM birth weight dashed horizontal line and the 37 week dashed vertical line, representing the demarcations for SGA and preterm we find a correspondence between SGA and preterm delivery, a widely known outcome. The clusters were named after this finding, as: Pre-term; Term, early and Term, full are from 37 weeks and over. Limitations: preterm deliveries account for only **```r prcnt_preterm```%** of the deliveries; we limited the lower gestational age range to 20 weeks(140 days) to exclude fetal non-viability.



## High Risk OB
Let's officially define "High Risk OB", based on maternal age greater than 35, diagnosis of HTN or Preeclampsia, DM and (for CSVS) multiple gestation and or non-vertex presentation. By these criteria, **```r prcnt_hghRsk```%** are classified as High Risk.

# Service Area using Zipcode

What is CSVS OB service area? Let's now look at where our patients come from using a zipcode information (99999 represents all others);
```{r echo=FALSE}
zip <- CreateTableOne(data = ob_data_tbl1,vars = "zip")
tableone::kableone(print(zip))
```

and a map of the County.


```{r echo=FALSE}
library(leaflet)
library(sf)
library(dplyr)
library(RColorBrewer)

# Load spatial and data
zip_code_sf <- readRDS("CSVS service area with Zipcode and Population  with sf and shp.RDS")
ob_data_map <- readRDS("Working OB Dataset.RDS")

# Summarize data by ZIP code
ob_data_map <- ob_data_map %>%
  count(zip)

# Convert ZIP codes to character
ob_data_map$zip <- as.character(ob_data_map$zip)
zip_code_sf$ZCTA5CE20 <- as.character(zip_code_sf$ZCTA5CE20)

# Convert zip_code_sf to WGS84 datum
zip_code_sf <- st_transform(zip_code_sf, crs = 4326)

# Perform the join
ob_data_map_joined <- zip_code_sf %>%
  left_join(ob_data_map, by = c("ZCTA5CE20" = "zip"))

# Check for missing values and handle them
ob_data_map_joined$n[is.na(ob_data_map_joined$n)] <- 0

# Create a color palette function
colorPalette <- colorBin(palette = "YlOrRd", domain = ob_data_map_joined$n, bins = 5)

# Generate the leaflet map
leaflet(data = ob_data_map_joined) %>%
  addTiles() %>%
  addPolygons(
    fillColor = ~colorPalette(n),
    color = "#BDBDC3",
    fillOpacity = 0.7,
    weight = 1,
    opacity = 1,
    highlight = highlightOptions(
      weight = 3,
      color = "#666",
      fillOpacity = 0.7,
      bringToFront = TRUE
    ),
    label = ~paste("ZIP Code:", ZCTA5CE20, "<br/>Count:", n),
    labelOptions = labelOptions(
      direction = 'auto',
      noHide = FALSE,
      textOnly = TRUE
    )
  ) %>%
  addLegend(
    pal = colorPalette, 
    values = ~n, 
    opacity = 0.7, 
    title = "Count",
    position = "bottomright"
  ) %>%
  setView(lng = -121.895, lat = 36.674, zoom = 9)

```

This map shows that zipcode 93908 sitting smack within "CSVS Territory" has extremely low deliveries. Information^[(source: <https://www.unitedstateszipcodes.org/93908/>, viewed 2024-05-27)] reveals that this zipcode (Salinas - Corral De Tierra):

* has primarily white residents

* has Median Household Income	$108,093

* has Median Home Value	$616,000.


93905 with the highest deliveries, on the other hand, has "primarily other race", with a medium household income of $41,607 and Median Home Value of $203,400.^[(source: <https://www.unitedstateszipcodes.org/93908/>, viewed 2024-05-27)]


We are going to continue the analysis of our data using zip-code distribution, Clustering and high Risk oB as examples before moving to generalized analyses.

##### How does zip code affect the distribution of outcomes like Preterm (derived from cluster analysis), High Risk OB, delivery method?

```{r}
ob_data_tbl1 <- readRDS("All Factored Complete Ready OB Dataset for Analytics.RDS") %>% 
  select(-adm_date, -delivery_date) %>% 
  mutate(cluster = as.factor(if_else(cluster == 2,1,0)))

strata_tbl_clst_zip <- CreateTableOne(data = ob_data_tbl1, strata = "cluster", vars = "zip")
#print(strata_tbl_clst, nonnormal = "cluster", cramVars = "cluster" )
kableone(print(strata_tbl_clst, nonnormal = "cluster", cramVars = "cluster" ), caption = "Distribution of Preterm by Zip code")
#kableExtra::kable(kableone(strta_zip_clst_prn), format = "html")

strata_tbl_hghRsk_zip <- CreateTableOne(data = ob_data_tbl1, strata = "hghRsk", vars = "zip")
#print(strata_tbl_hghRsk, nonnormal = "cluster", cramVars = "hghRsk" )
kableone(print(strata_tbl_hghRsk, cramVars = "hghRsk"), caption = "Distribution of High Risk OB by Zip code")
#kableExtra::kable(kableone(strta_zip_hghRsk_prn), format = "html")

strata_tbl_del_zip <- CreateTableOne(data = ob_data_tbl1, strata = "del_method_cnsldt", vars = "zip")
#print(strata_tbl_hghRsk, nonnormal = "cluster", cramVars = "hghRsk" )
kableone(print(strata_tbl_del_zip, cramVars = "del_method_cnsldt"), caption = "Distribution of Delivery Methods by Zip code")
#kableExtra::kable(kableone(strta_zip_hghRsk_prn), format = "html")

```

The answer is, there is no significant difference in distribution.

What about the High Risk OB and the outcomes of cluster & Delivery Method?

```{r echo=FALSE}
strata_tbl_clst_rsk <- CreateTableOne(data = ob_data_tbl1, strata = "cluster", vars = "hghRsk")
#print(strata_tbl_hghRsk, nonnormal = "cluster", cramVars = "hghRsk" )
kableone(print(strata_tbl_clst_rsk, nonnormal = "cluster", cramVars = "hghRsk"), caption = "Distribution of Preterm by High Risk OB")
#kableExtra::kable(kableone(strta_zip_hghRsk_prn), format = "html")

strata_tbl_del_rsk <- CreateTableOne(data = ob_data_tbl1, strata = "del_method_cnsldt", vars = "hghRsk")
#print(strata_tbl_hghRsk, nonnormal = "cluster", cramVars = "hghRsk" )
kableone(print(strata_tbl_del_rsk, nonnormal = "del_method_cnsldt", cramVars = "hghRsk"), caption = "Distribution of Delivery Method by High Risk OB")
#kableExtra::kable(kableone(strta_zip_hghRsk_prn), format = "html")

```

With a p-value <0.001, a statistically significant difference is obvious in the distribution of Cesarean sections compared to Vaginal deliveries among High Risk OB.

Finally same question for Preterm and outcomes of High Risk and Delivery Method:

```{r echo=FALSE}

strata_tbl_rsk_clst <- CreateTableOne(data = ob_data_tbl1, strata = "hghRsk", vars = "cluster")
#print(strata_tbl_hghRsk, nonnormal = "cluster", cramVars = "hghRsk" )
kableone(print(strata_tbl_rsk_clst, nonnormal = "cluster", cramVars = "hghRsk"), caption = "Distribution of Preterm by High Risk OB")
#kableExtra::kable(kableone(strta_zip_hghRsk_prn), format = "html")

strata_tbl_del_clst <- CreateTableOne(data = ob_data_tbl1, strata = "del_method_cnsldt", vars = "cluster")
#print(strata_tbl_hghRsk, nonnormal = "cluster", cramVars = "hghRsk" )
kableone(print(strata_tbl_del_clst, nonnormal = "cluster", cramVars = "del_method_cnsldt"), caption = "Distribution of Preterm by Delivery Method")
#kableExtra::kable(kableone(strta_zip_hghRsk_prn), format = "html")

```

Here, there is no significant difference.

#### Conclusion: The distribution of the outcome, Delivery Method, is significantly different among High Risk OB, with delivery by Cesarean Sections significantly higher in those identified as High Risk OB. The other permutations of the variables did not result in significant differences.

* We conclude that the incidence of delivery by Cesarean section is higher among High Risk OB patients when compared to vaginal delivery..



# Correlation Analysis (Spearman method)
Correlation
: Correlation is a statistical measure that describes the strength and direction of a relationship between two variables. It ranges from -1 to 1, where values close to 1 or -1 indicate strong positive or negative relationships, respectively, and values close to 0 indicate no relationship.

We have prepared an interactive table to facilate the exercise. Keep in mind that the included p-value detetmines whether there is a statistical significance or not. ***There are 15x14 pair-combinations, so, think, parsimony.***


```{r setup, include=FALSE}
library(shiny)
library(XICOR)
library(dplyr)
library(ggplot2)
library(DT)

# Assuming the dataset is loaded here
ob_data_clst_xi <- readRDS("All Factored Complete Ready OB Dataset for Analytics.RDS") %>%
  dplyr::select(zip, lbr_type_cnsldt, membrane_rupture, intrapartal_conditions,
                presentation_cnsldt, conditions_cnsldt, uds_age, adm_to_del_tm_cat, hghRsk, del_method_cnsldt, cluster,
                age, grav, para, diff_grav_para) %>%
  mutate(across(c(zip, lbr_type_cnsldt, membrane_rupture, intrapartal_conditions,
                  presentation_cnsldt, conditions_cnsldt, uds_age, adm_to_del_tm_cat, hghRsk, del_method_cnsldt, cluster), as.factor)) %>%
  mutate(across(c(zip, lbr_type_cnsldt, membrane_rupture, intrapartal_conditions,
                  presentation_cnsldt, conditions_cnsldt, uds_age, adm_to_del_tm_cat, hghRsk, del_method_cnsldt, cluster), as.numeric))
```


```{r echo=FALSE}
#| context: server
output$xiCorPlot <- renderPlot({
  req(input$var1, input$var2)
  if (input$var1 != input$var2) {
    spearman_result <- cor.test(ob_data_clst_xi[[input$var1]], ob_data_clst_xi[[input$var2]], method = "spearman")
    spearman_value <- spearman_result$estimate
    p_value <- spearman_result$p.value
    
    xi_data <- data.frame(Variable1 = input$var1, Variable2 = input$var2, Spearman = spearman_value, P_Value = p_value)
    
    ggplot(xi_data, aes(x = Variable1, y = Spearman, fill = Variable2)) +
      geom_col() +
      geom_text(aes(label = paste("Spearman:", round(Spearman, 2), "\nP-value:", round(P_Value, 4))), vjust = -0.5) +
      labs(title = paste("Spearman Correlation between", input$var1, "and", input$var2),
           x = "Variable Pair", y = "Spearman Correlation") +
      theme_minimal()
  } else {
    ggplot() + labs(title = "Please select two different variables")
  }
})

output$xiCorTable <- DT::renderDT({
  req(input$var1, input$var2)
  if (input$var1 != input$var2) {
    spearman_result <- cor.test(ob_data_clst_xi[[input$var1]], ob_data_clst_xi[[input$var2]], method = "spearman")
    spearman_value <- spearman_result$estimate
    p_value <- spearman_result$p.value
    
    datatable(data.frame(Variable1 = input$var1, Variable2 = input$var2, Spearman = round(spearman_value, 2), P_Value = round(p_value, 4)), options = list(pageLength = 5, scrollX = TRUE))
  } else {
    datatable(data.frame(Message = "Select different variables"), options = list(pageLength = 5, scrollX = TRUE))
  }
})


```

```{r echo=FALSE}
# Define the UI layout
fluidPage(
  titlePanel("Interactive Xi Correlation Analysis"),
  sidebarLayout(
    sidebarPanel(
      selectInput("var1", "Select the first variable:", choices = names(ob_data_clst_xi)),
      selectInput("var2", "Select the second variable:", choices = names(ob_data_clst_xi))
    ),
    mainPanel(
      tabsetPanel(
        tabPanel("Spearman Correlation Plot", plotOutput("xiCorPlot")),
        tabPanel("Spearman Correlation Table", DTOutput("xiCorTable"))
      )
    )
  )
)


```


# Survival or Time-to_Event (TTE) Analysis -- Shiny App

Survival or Time-to_Event (TTE) Analysis
: Survival analysis, or time-to-event analysis, is a statistical method used to analyze the expected duration until one or more events occur, such as death or failure. It involves the use of survival functions to estimate the probability of surviving past a certain time point. The Kaplan-Meier (KM) estimator is a non-parametric statistic used to estimate the survival function from observed survival times. Cumulative hazard (cumHaz) functions represent the accumulated risk of the event over time. Hazard ratios (HR) compare the hazard rates between two groups, indicating the relative likelihood of the event occurring in one group compared to another.



```{r echo=FALSE, warning=FALSE, message=FALSE}
source(file = "partiallyWrkingRShiny5_22.R")
shinyApp(ui = ui, server = server)
```


# 
# # Zip Code effect
# ## Cluster (preterm)
# ```{r echo=FALSE, message=FALSE, warning=FALSE}
# # Load necessary libraries
# library(broom)
# library(ggplot2)
# 
# ob_data_fctr <- readRDS("All Factored Complete Ready OB Dataset for Analytics.RDS")
# 
# # Derive the binary outcome from the cluster variable
# ob_data_fctr$cluster <- ifelse(ob_data_fctr$cluster == 2, 1, 0)
# 
# # Convert the binary outcome to a factor
# ob_data_fctr$binary_outcome <- as.factor(ob_data_fctr$cluster)
# 
# # Calculate the frequency of each zip code
# zip_freq <- table(ob_data_fctr$zip)
# 
# # Define the frequency threshold
# threshold <- 60
# 
# # Create a new column categorizing zip codes based on the threshold
# ob_data_fctr$zip_category <- ifelse(zip_freq[ob_data_fctr$zip] >= threshold, 
#                                     as.character(ob_data_fctr$zip), 
#                                     "Other")
# 
# # Convert the new zip_category column to a factor
# ob_data_fctr$zip_category <- as.factor(ob_data_fctr$zip_category)
# 
# # Fit the logistic regression model with the specified predictor variables
# suppressWarnings({
# model <- glm(binary_outcome ~ zip_category + age + grav + para + gender + uds_age + hghRsk, 
#              data = ob_data_fctr, family = binomial(), )
# 
# })
# #summary(model)
# 
# # Load necessary libraries
# library(ggplot2)
# 
#  # Extract coefficients and their confidence intervals
# coef_df <- data.frame(
#    term = names(coef(model)),
#    estimate = coef(model),
#    conf.low = confint(model)[, 1],
#    conf.high = confint(model)[, 2]
#  )
# # 
# # # Plot coefficients
# #  ggplot(coef_df, aes(x = term, y = estimate)) +
# #    geom_point() +
# #    geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
# #    coord_flip() +
# #    theme_minimal() +
# #    labs(title = "Logistic Regression Coefficients",
# #         x = "Predictors",
# #         y = "Coefficient Estimate")
# # 
# 
# ##################################

# Tidy the model output
tidy_model <- tidy(model, conf.int = TRUE)

# Add significance indicators
tidy_model$significance <- cut(tidy_model$p.value, 
                               breaks = c(-Inf, 0.001, 0.01, 0.05, Inf), 
                               labels = c("***", "**", "*", ""))


# Plot coefficients with coefficient values and p-values
ggplot(tidy_model, aes(x = reorder(term, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  geom_text(aes(label = paste0(round(estimate, 2), "\n(p=", format.pval(p.value), ")")),
            vjust = -0.5, hjust = 1) +
  coord_flip() +
  theme_minimal() +
  labs(title = "Logistic Regression Coefficients with P-values",
       x = "Predictors",
       y = "Coefficient Estimate") +
  theme(axis.text.y = element_text(size = 10)) +
  ylim(c(-1, 1))  # Adjust this range as needed based on your data

# Install and load necessary packages
#install.packages("broom")
library(broom)
library(ggplot2)

# Fit the logistic regression model (assuming model is already fitted as in your context)
# model <- glm(binary_outcome ~ zip_category + age + grav + para + gender + uds_age + hghRsk + diff_grav_para, 
#              data = ob_data_fctr, family = binomial())

# Tidy the model output
tidy_model <- tidy(model, conf.int = TRUE)

# Add significance indicators
tidy_model$significance <- cut(tidy_model$p.value, 
                               breaks = c(-Inf, 0.001, 0.01, 0.05, Inf), 
                               labels = c("***", "**", "*", ""))

# Plot coefficients with coefficient values and p-values
ggplot(tidy_model, aes(x = reorder(term, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  geom_text(aes(label = paste0(round(estimate, 2), "\n(p=", format.pval(p.value), ")")),
            vjust = -0.5, hjust = 1) +
  coord_flip() +
  theme_minimal() +
  labs(title = "Logistic Regression Coefficients with P-values",
       x = "Predictors",
       y = "Coefficient Estimate") +
  theme(axis.text.y = element_text(size = 10)) +
  ylim(c(-1, 1))  # Adjust this range as needed based on your data

```

```{r echo = FALSE}
## HghRsk Effect

library(broom)
library(ggplot2)

ob_data_fctr$binary_outcome_hgh <- as.factor(ob_data_fctr$hghRsk)

# Fit the logistic regression model (assuming model is already fitted as in your context)
suppressWarnings({
model_hgh <- glm(binary_outcome_hgh ~ zip_category + age + grav + para + gender + uds_age + cluster, 
            data = ob_data_fctr, family = binomial())
})
#summary(model_hgh)


# Tidy the model output
tidy_model <- tidy(model_hgh, conf.int = TRUE)

# Add significance indicators
tidy_model$significance <- cut(tidy_model$p.value, 
                               breaks = c(-Inf, 0.001, 0.01, 0.05, Inf), 
                               labels = c("***", "**", "*", ""))


# Plot coefficients with coefficient values and p-values
ggplot(tidy_model, aes(x = reorder(term, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  geom_text(aes(label = paste0(round(estimate, 2), "\n(p=", format.pval(p.value), ")")),
            vjust = -0.5, hjust = 1) +
  coord_flip() +
  theme_minimal() +
  labs(title = "Logistic Regression Coefficients with P-values",
       x = "Predictors",
       y = "Coefficient Estimate") +
  theme(axis.text.y = element_text(size = 10)) +
  ylim(c(-1, 1))  # Adjust this range as needed based on your data

# Install and load necessary packages
#install.packages("broom")
library(broom)
library(ggplot2)

# Fit the logistic regression model (assuming model is already fitted as in your context)
# model <- glm(binary_outcome ~ zip_category + age + grav + para + gender + uds_age + hghRsk, 
#              data = ob_data_fctr, family = binomial())

# Tidy the model output
tidy_model <- tidy(model_hgh, conf.int = TRUE)

# Add significance indicators
tidy_model$significance <- cut(tidy_model$p.value, 
                               breaks = c(-Inf, 0.001, 0.01, 0.05, Inf), 
                               labels = c("***", "**", "*", ""))

# Plot coefficients with coefficient values and p-values
ggplot(tidy_model, aes(x = reorder(term, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  geom_text(aes(label = paste0(round(estimate, 2), "\n(p=", format.pval(p.value), ")")),
            vjust = -0.5, hjust = 1) +
  coord_flip() +
  theme_minimal() +
  labs(title = "Logistic Regression Coefficients with P-values",
       x = "Predictors",
       y = "Coefficient Estimate") +
  theme(axis.text.y = element_text(size = 10)) +
  ylim(c(-1, 1))  # Adjust this range as needed based on your data


# Predict probabilities
ob_data_fctr$predicted_prob <- predict(model_hgh, type = "response")

# Plot predicted probabilities against age (for example)
prob_plot <- ggplot(ob_data_fctr, aes(x = age, y = predicted_prob)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess", color = "blue") +
  theme_minimal() +
  labs(title = "Predicted Probabilities by age",
       x = "Age",
       y = "Predicted Probability")

# # Compute ROC curve
# roc_curve <- roc(ob_data_fctr$binary_outcome_hgh, ob_data_fctr$predicted_prob)
# 
# # Plot ROC curve
# roc_plot <- plot(roc_curve, main = "ROC Curve", col = "blue")
# abline(a = 0, b = 1, lty = 2, col = "red") # diagonal line
# 
# # Display plots
# print(coef_plot)
# print(prob_plot)
# roc_plot
```

# Hospital admission, Delivery, conditions and Events.

## Time-to-Event (TTE) Analysis

### Definitions

The goal of our data analytics is to understand how various factors affect pregnancy course and delivery in our patient population. We will use NMC data as above. Before we proceed, please be familiar with these definitions:

(@) Event: **Delivery**

There is an associated delivery date and delivery time that defines the event

(@) Intervention: **Admission to the NMC**

A date-time is associated with Intervention

(@) Interval: **Duration** of time between Intervention and Event.

(@) Time: any **slice** of, or **point** , in time (not Duration) within Interval

(@) Survival: **"Survived" Event** at any given Time

This means "survived" delivery, ie., delivery has not occurred at specified Time, or, *undelivered*.

These definitions will facilitate the interpretation of our analyses when we use the popular analytic method called Survival Analysis (SA) or Time to Event (TTE) analysis.




### Check Survival, K-M,Cumulative Hazard and Hazard Ratio

```{r echo=FALSE}
# Load necessary libraries
library(survival)
library(survminer)
library(ggplot2)
library(myRFunctions)


ob_data_srvl = readRDS("All Factored Complete Ready OB Dataset for Analytics.RDS")

# Fit Cox Proportional Hazards Model
cox_model <- coxph(Surv(time, event) ~ zip + hghRsk + conditions_cnsldt + intrapartal_events + age + grav + para, data = ob_data_srvl)
#summary(cox_model)

# Visualize the survival curves
ggsurv <- ggsurvplot(
  survfit(cox_model), 
  data = ob_data_srvl,
  pval = TRUE,
  conf.int = TRUE,
  risk.table = TRUE,
  ggtheme = theme_minimal()
)

# Customize the plot using ggplot2
ggsurv$plot +
  labs(
    title = "Survival Analysis",
    x = "Time",
    y = "Survival Probability"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.title.x = element_text(face = "bold"),
    axis.title.y = element_text(face = "bold")
  )



```

#### with left censoring
```{r echo=FALSE}
# Load necessary libraries
library(survival)
library(survminer)
library(ggplot2)


# # Ensure necessary columns are factors
# ob_data_srvl$zip <- as.factor(ob_data_srvl$zip)
# ob_data_srvl$hghRsk <- as.factor(ob_data_srvl$hghRsk)
# ob_data_srvl$conditions_cnsldt <- as.factor(ob_data_srvl$conditions_cnsldt)
# ob_data_srvl$intrapartal_events <- as.factor(ob_data_srvl$intrapartal_events)

# Filter out records with non-positive time values
ob_data_srvl <- readRDS("All Factored Complete Ready OB Dataset for Analytics.RDS") %>%
  filter(time >= 0)

# Identify the top 5 ZIP codes based on frequency
top_zip_codes <- ob_data_srvl %>%
  count(zip) %>%
  top_n(5, wt = n) %>%
  pull(zip)

print(top_zip_codes)

# Filter the data to include only the top 5 ZIP codes
filtered_data <- ob_data_srvl %>%
  filter(zip %in% top_zip_codes)



# Fit Cox Proportional Hazards Model with Left-Censoring
# Fit Cox Proportional Hazards Model with Left-Censoring
cox_model_left_censor <- coxph(Surv(time, event) ~ age + strata(zip) + hghRsk + conditions_cnsldt + intrapartal_events, data = filtered_data)
#summary(cox_model_left_censor)

# Fit the survival curves using survfit
surv_fit <- survfit(cox_model_left_censor)

# Visualize the survival curves with left-censoring
ggsurv_left_censor <- ggsurvplot(
  surv_fit, 
  data = filtered_data,
  # pval = TRUE, # Commented out as mentioned
  conf.int = FALSE,
  risk.table = TRUE,
  ggtheme = theme_minimal()
)

# Customize the stratified plot
ggsurv_left_censor$plot +
  labs(
    title = "Survival Analysis with Top 5 ZIP Codes",
    x = "Time",
    y = "Survival Probability"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.title.x = element_text(face = "bold"),
    axis.title.y = element_text(face = "bold")
  )

```

####KM

```{r echo=FALSE}
# Load necessary libraries
library(survival)
library(survminer)
library(ggplot2)
library(dplyr)

# Identify the top 5 ZIP codes based on frequency
top_zip_codes <- ob_data_srvl %>%
  count(zip) %>%
  top_n(5, wt = n) %>%
  pull(zip)

# Filter the data to include only the top 5 ZIP codes
filtered_data <- ob_data_srvl %>%
  filter(zip %in% top_zip_codes) %>%
  mutate(
    zip = as.factor(zip),
    hghRsk = as.factor(hghRsk),
    conditions_cnsldt = as.factor(conditions_cnsldt),
    intrapartal_events = as.factor(intrapartal_events)
  )

# Simplify the stratification to a single variable, e.g., zip
km_fit <- survfit(Surv(time, event) ~ zip, data = filtered_data)

# Plot the Kaplan-Meier survival curves
km_plot <- ggsurvplot(
  km_fit,
  data = filtered_data,
  conf.int = FALSE,
  risk.table = FALSE,
  ggtheme = theme_minimal(),
  title = "Kaplan-Meier Survival Curves by ZIP",
  xlab = "Time",
  ylab = "Survival Probability"
)

# Print the Kaplan-Meier plot
print(km_plot) 



```

#### cumHAZ

```{r echo=FALSE}
# Load necessary libraries
library(survival)
library(survminer)
library(ggplot2)
library(dplyr)
library(myRFunctions)

# Identify the top 5 ZIP codes based on frequency
top_zip_codes <- ob_data_srvl %>%
  count(zip) %>%
  top_n(5, wt = n) %>%
  pull(zip)

# Filter the data to include only the top 5 ZIP codes
filtered_data <- ob_data_srvl %>%
  filter(zip %in% top_zip_codes) %>%
  mutate(
    zip = as.factor(zip),
    hghRsk = as.factor(hghRsk),
    conditions_cnsldt = as.factor(conditions_cnsldt),
    intrapartal_events = as.factor(intrapartal_events)
  )

# Fit cumulative hazard functions
cumhaz_fit <- survfit(Surv(time, event) ~ zip, data = filtered_data)
cumhaz_plot <- ggsurvplot(
  cumhaz_fit,
  data = filtered_data,
  fun = "cumhaz",
  conf.int = FALSE,
  risk.table = FALSE,
  ggtheme = theme_minimal(),
  title = "Cumulative Hazard Functions by ZIP",
  xlab = "Time",
  ylab = "Cumulative Hazard"
)
print(cumhaz_plot)

# Fit Cox Proportional Hazards Model
cox_model_hr <- coxph(Surv(time, event) ~ zip + hghRsk + conditions_cnsldt + intrapartal_events, data = filtered_data)
#summary(cox_model_hr)
# myRFunctions::ggforest3(cox_model_hr)
# ggforest(cox_model_hr)
ggadjustedcurves(cox_model_hr)
# Extract hazard ratios and confidence intervals
hr_table <- summary(cox_model)$coefficients
hr_df <- as.data.frame(hr_table)
hr_df$HR <- exp(hr_df$coef)
hr_df$lower_95 <- exp(hr_df$coef - 1.96 * hr_df$`se(coef)`)
hr_df$upper_95 <- exp(hr_df$coef + 1.96 * hr_df$`se(coef)`)

# Plot the hazard ratios using ggplot2
hr_plot <- ggplot(hr_df, aes(x = rownames(hr_df), y = HR)) +
  geom_point() +
  geom_errorbar(aes(ymin = lower_95, ymax = upper_95), width = 0.2) +
  theme_minimal() +
  labs(
    title = "Hazard Ratios with 95% Confidence Intervals",
    x = "Variables",
    y = "Hazard Ratio (HR)"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(hr_plot)

```

```{r echo=FALSE}
# Define the custom ggforest3 function (if not already defined)
ggforest3 <- function(cox_model, data, main = "Hazard Ratios", fontsize = 0.7) {
  library(myRFunctions)
  
  # Extract coefficients and their confidence intervals
  coef_df <- summary(cox_model)$coefficients
  coef_df <- as.data.frame(coef_df)
  coef_df$Variable <- rownames(coef_df)
  coef_df$HR <- exp(coef_df$coef)
  coef_df$lower_95 <- exp(coef_df$coef - 1.96 * coef_df$`se(coef)`)
  coef_df$upper_95 <- exp(coef_df$coef + 1.96 * coef_df$`se(coef)`)

  # Plot the hazard ratios using ggplot2
  hr_plot <- ggplot(coef_df, aes(x = reorder(Variable, HR), y = HR)) +
    geom_point() +
    geom_errorbar(aes(ymin = lower_95, ymax = upper_95), width = 0.2) +
    theme_minimal() +
    labs(
      title = main,
      x = "Variables",
      y = "Hazard Ratio (HR)"
    ) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    coord_flip() # Flip coordinates for better readability
  
  return(hr_plot)
}

# Use the custom ggforest3 function to plot the hazard ratios
hr_plot <- ggforest3(cox_model, filtered_data)
print(hr_plot)

##Diff version hazard plot

# Load necessary libraries
library(survival)
library(dplyr)

# Identify the top 5 ZIP codes based on frequency
top_zip_codes <- ob_data_srvl %>%
  count(zip) %>%
  top_n(5, wt = n) %>%
  pull(zip)

# Filter the data to include only the top 5 ZIP codes
filtered_data <- ob_data_srvl %>%
  filter(zip %in% top_zip_codes) %>%
  mutate(
    zip = as.factor(zip),
    hghRsk = as.factor(hghRsk),
    conditions_cnsldt = as.factor(conditions_cnsldt),
    intrapartal_events = as.factor(intrapartal_events)
  )

# Check for missing values
# sum(is.na(filtered_data$zip))
# sum(is.na(filtered_data$hghRsk))
# sum(is.na(filtered_data$conditions_cnsldt))
# sum(is.na(filtered_data$intrapartal_events))
# sum(is.na(filtered_data$time))
# sum(is.na(filtered_data$event))

# Fit Cox Proportional Hazards Model
cox_model <- coxph(Surv(time, event) ~ zip + hghRsk + conditions_cnsldt + intrapartal_events, data = filtered_data)
#summary(cox_model)

# Define the custom ggforest3 function with HR values and p-values
ggforest3 <- function(cox_model, data, main = "Hazard Ratios") {
  # Extract coefficients and their confidence intervals
  coef_summary <- summary(cox_model)$coefficients
  coef_df <- as.data.frame(coef_summary)
  coef_df$Variable <- rownames(coef_df)
  coef_df$HR <- exp(coef_df$coef)
  coef_df$lower_95 <- exp(coef_df$coef - 1.96 * coef_df$`se(coef)`)
  coef_df$upper_95 <- exp(coef_df$coef + 1.96 * coef_df$`se(coef)`)
  coef_df$p_value <- coef_df$`Pr(>|z|)`
  
  # Handle any potential missing values
  coef_df <- na.omit(coef_df)
  
  # Set up the plotting area
  par(mar = c(5, 12, 4, 2))
  
  # Plot the hazard ratios
  plot(
    coef_df$HR,
    seq_along(coef_df$HR),
    xlim = c(min(coef_df$lower_95), max(coef_df$upper_95)),
    pch = 16,
    xlab = "Hazard Ratio (HR)",
    ylab = "",
    main = main,
    yaxt = "n"
  )
  
  # Add error bars
  arrows(
    coef_df$lower_95, seq_along(coef_df$HR),
    coef_df$upper_95, seq_along(coef_df$HR),
    angle = 90, code = 3, length = 0.05
  )
  
  # Add y-axis labels
  axis(2, at = seq_along(coef_df$HR), labels = coef_df$Variable, las = 2)
  
  # Add a vertical line at HR = 1
  abline(v = 1, col = "red", lty = 2)
  
  # Add text labels for HR values and p-values
  text(coef_df$HR, seq_along(coef_df$HR), 
       labels = sprintf("%.2f", coef_df$HR), pos = 4, cex = 0.8)
  text(coef_df$HR, seq_along(coef_df$HR) - 0.3, 
       labels = sprintf("p=%.3f", coef_df$p_value), pos = 4, cex = 0.7)
}

# Plot the hazard ratios using the custom ggforest3 function
ggforest3(cox_model, filtered_data)



```




```{r echo=FALSE}
# library(tableone)
# library(dplyr)
# 
# # Load the dataset
# ob_data_fctr <- readRDS("All Factored Complete Ready OB Dataset for Analytics.RDS") %>% 
#   select(-adm_date, -delivery_date)
# 
# library(tableone)
# library(dplyr)
# 
# # Load the dataset
# ob_data_fctr <- readRDS("All Factored Complete Ready OB Dataset for Analytics.RDS")
# 
# # Define the variables and group variable
# vars <- names(ob_data_fctr)
# group_var <- "cluster"  # Use 'cluster' as the grouping variable
# 
# # Create the tableone object
# table_one <- CreateTableOne(vars = vars, strata = group_var, data = ob_data_fctr, addOverall = TRUE)
# 
# # Print the tableone object
# print(table_one)
# 


```

